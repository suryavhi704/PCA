# ğŸ€ Principal Component Analysis (PCA) on Basketball Player Data

This repository contains a hands-on implementation of **Principal Component Analysis (PCA)** as part of a session conducted by **Intellipaat**. The project focuses on dimensionality reduction and performance comparison using a dataset of basketball players.

## ğŸ” Project Overview

In this project, I explored the effectiveness of PCA in simplifying high-dimensional data while retaining the most important information. The dataset comprises various performance metrics of basketball players, and the goal is to use this data to predict an outcome using **Logistic Regression** â€” once with PCA applied and once without.

## âœ… What I Learned

- ğŸ“Š **Data Preprocessing**  
  Cleaned and prepared the dataset for analysis, including handling missing values and scaling features.

- ğŸ§® **Mean Centering**  
  Centralized the data around the mean to ensure that PCA effectively captures variance.

- ğŸ“‰ **Principal Component Analysis (PCA)**  
  Applied PCA to reduce the dimensionality of the dataset while maintaining the core information.

- ğŸ¤– **Model Building with Logistic Regression**  
  Built and evaluated two logistic regression models:
  - One using the original feature set.
  - One using PCA-transformed features.

## ğŸ“ˆ Key Findings

- **PCA-enhanced data outperformed the raw dataset in prediction accuracy.**  
  The PCA model captured the essential structure of the data more effectively, enabling better classification results.

- **Dimensionality reduction not only improved performance but also enhanced model interpretability and reduced training time.**

## ğŸ§ª Technologies Used

- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib / Seaborn (for visualization)

## ğŸš€ How to Run

```bash
git clone (https://github.com/suryavhi704/PCA).git
cd pca-basketball-analysis
pip install -r requirements.txt
python pca_logistic_regression.py
```

## ğŸ“Œ Conclusion

This project showcases the practical application of PCA in improving model performance and simplifying complex datasets. It's a great example of how dimensionality reduction techniques can elevate traditional machine learning workflows.
